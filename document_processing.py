# -*- coding: utf-8 -*-
"""document_processing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zng9sUDNtwdXHTO7v6trSWIcsOoxn7dB
"""

# !pip install sentence-transformers transformers faiss-cpu langchain
# !pip install python-dotenv
# !pip install langchain
# !pip install faiss-gpu  # or faiss-cpu if you're using a CPU
# !pip install streamlit
# !pip install python-docx
# !pip install -U langchain-community
# !pip install -U langchain-huggingface
# !pip install --upgrade sentence-transformers langchain faiss-cpu

from dotenv import load_dotenv
import os
import json
import docx
import re
import torch
import logging
import numpy as np
from transformers import pipeline
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import traceback  # Added for error handling

logging.basicConfig(level=logging.DEBUG)
load_dotenv()

# Function to preprocess text
def preprocess_text(text):
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\n+', '\n', text)
    return text.strip()

# Function to read text from a .docx file
def read_docx(file_path):
    doc = docx.Document(file_path)
    text = ""
    for paragraph in doc.paragraphs:
        text += paragraph.text + "\n"
    return text

# Function to load Q&A pairs from JSON file
def load_qa_pairs(file_path):
    with open(file_path, 'r') as file:
        return json.load(file)

# Function to get answer from Q&A pairs
def get_answer_from_qa_pairs(query, qa_pairs):
    for qa in qa_pairs:
        if query.lower() in qa['question'].lower():
            return qa['answer']
    return None

# Function to get text data from backend
def get_text_from_backend():
    # file_path = os.getenv('DOCX_FILE_PATH', '/content/Corpus.docx')  # Get file path from environment variable
    file_path = os.getenv('DOCX_FILE_PATH', r"C:\Users\User\Downloads\Wines Chatbot\Corpus.docx")
    text_data = read_docx(file_path)
    text_data = preprocess_text(text_data)
    return text_data

def get_answer_from_document(query, text_data):
    logging.debug("Starting document processing")

    # Preprocess text
    text_data = preprocess_text(text_data)

    # Split text into chunks
    chunk_size = 1000
    chunk_overlap = 200
    text_chunks = []
    for i in range(0, len(text_data), chunk_size - chunk_overlap):
        chunk = text_data[i:i + chunk_size]
        text_chunks.append(chunk)

    logging.debug(f"Number of Chunks: {len(text_chunks)}")
    logging.debug(f"Sample Chunks: {text_chunks[:3]}")  # Log a few chunks

    if not text_chunks:
        return "No relevant text chunks found."

    # Load RoBERTa model and tokenizer
    model_name = 'deepset/roberta-base-squad2'
    qa_pipeline = pipeline("question-answering", model=model_name, tokenizer=model_name)

    # Process each chunk and find the most relevant one
    best_answer = ""
    highest_score = 0

    for chunk in text_chunks:
        try:
            response = qa_pipeline(question=query, context=chunk)
            score = response['score']
            if score > highest_score:
                highest_score = score
                best_answer = response.get('answer', "No answer found in this chunk.")
        except Exception as e:
            logging.error(f"Error processing chunk: {e}")
            continue

    if best_answer:
        return best_answer

    return "For more details, click on the link: https://jessupcellars.com/ or contact (707) 944-5620"

def process_query(query):
    try:
        logging.debug(f"Processing query: {query}")

        qa_pairs_file_path = os.getenv('QA_PAIRS_FILE_PATH', r"C:\Users\User\Downloads\Wines Chatbot\merged_qa_pairs.json")
        logging.debug(f"Loading Q&A pairs from: {qa_pairs_file_path}")
        qa_pairs = load_qa_pairs(qa_pairs_file_path)

        logging.debug("Retrieving text data from backend")
        text_data = get_text_from_backend()

        logging.debug("Checking Q&A pairs")
        answer = get_answer_from_qa_pairs(query, qa_pairs)
        if answer:
            logging.debug(f"Answer from Q&A pairs: {answer}")
            return answer

        logging.debug("Checking document for answer")
        if text_data:
            answer = get_answer_from_document(query, text_data)
            logging.debug(f"Answer from document: {answer}")
            return answer

        return "For more details, click on the link: https://jessupcellars.com/ or contact (707) 944-5620"
    except Exception as e:
        error_message = traceback.format_exc()
        logging.error(f"Error in process_query: {error_message}")
        raise